#!/usr/bin/env python3
"""
æµ‹è¯• Factory Proxy çš„ OpenAI å…¼å®¹æ¥å£
ä½¿ç”¨æ ‡å‡† OpenAI Python SDK
"""

from openai import OpenAI
import sys

def test_basic_chat():
    """æµ‹è¯•åŸºç¡€å¯¹è¯"""
    print("ğŸ§ª æµ‹è¯• 1: åŸºç¡€å¯¹è¯")
    print("-" * 50)
    
    client = OpenAI(
        api_key="your-factory-key",
        base_url="http://localhost:8003/v1"
    )
    
    try:
        response = client.chat.completions.create(
            model="claude-sonnet-4-5-20250929",
            messages=[
                {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç”¨ä¸­æ–‡ç®€çŸ­å›å¤"}
            ],
            max_tokens=50
        )
        
        print(f"âœ… æ¨¡å‹: {response.model}")
        print(f"âœ… ID: {response.id}")
        print(f"âœ… å›å¤: {response.choices[0].message.content}")
        print(f"âœ… Tokenä½¿ç”¨: {response.usage.total_tokens} (è¾“å…¥: {response.usage.prompt_tokens}, è¾“å‡º: {response.usage.completion_tokens})")
        print()
        return True
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        return False

def test_with_system():
    """æµ‹è¯•å¸¦ system æ¶ˆæ¯"""
    print("ğŸ§ª æµ‹è¯• 2: System æ¶ˆæ¯")
    print("-" * 50)
    
    client = OpenAI(
        api_key="your-factory-key",
        base_url="http://localhost:8003/v1"
    )
    
    try:
        response = client.chat.completions.create(
            model="claude-sonnet-4-5-20250929",
            messages=[
                {"role": "system", "content": "You are a helpful math tutor. Answer briefly."},
                {"role": "user", "content": "What is 7 * 8?"}
            ],
            max_tokens=30,
            temperature=0.7
        )
        
        print(f"âœ… å›å¤: {response.choices[0].message.content}")
        print(f"âœ… Finish reason: {response.choices[0].finish_reason}")
        print()
        return True
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        return False

def test_multi_turn():
    """æµ‹è¯•å¤šè½®å¯¹è¯"""
    print("ğŸ§ª æµ‹è¯• 3: å¤šè½®å¯¹è¯")
    print("-" * 50)
    
    client = OpenAI(
        api_key="your-factory-key",
        base_url="http://localhost:8003/v1"
    )
    
    try:
        response = client.chat.completions.create(
            model="claude-sonnet-4-5-20250929",
            messages=[
                {"role": "user", "content": "My name is Alice"},
                {"role": "assistant", "content": "Nice to meet you, Alice!"},
                {"role": "user", "content": "What's my name?"}
            ],
            max_tokens=20
        )
        
        content = response.choices[0].message.content
        print(f"âœ… å›å¤: {content}")
        
        # æ£€æŸ¥æ˜¯å¦è®°ä½äº†åå­—
        if "Alice" in content or "alice" in content.lower():
            print("âœ… æˆåŠŸè®°ä½ä¸Šä¸‹æ–‡ï¼")
        else:
            print("âš ï¸  å¯èƒ½æœªæ­£ç¡®å¤„ç†ä¸Šä¸‹æ–‡")
        print()
        return True
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        return False

if __name__ == "__main__":
    print("=" * 50)
    print("Factory Proxy - OpenAI SDK å…¼å®¹æ€§æµ‹è¯•")
    print("=" * 50)
    print()
    
    results = []
    results.append(test_basic_chat())
    results.append(test_with_system())
    results.append(test_multi_turn())
    
    print("=" * 50)
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {sum(results)}/{len(results)} é€šè¿‡")
    print("=" * 50)
    
    sys.exit(0 if all(results) else 1)