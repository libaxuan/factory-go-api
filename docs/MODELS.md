# æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨

## âš ï¸ é‡è¦è¯´æ˜

**ç»è¿‡ 2025-10-08 çœŸå® API æµ‹è¯•éªŒè¯ï¼ŒFactory AI ç›®å‰ä»…æ”¯æŒä»¥ä¸‹ 3 ä¸ª Claude æ¨¡å‹ã€‚**

é€šè¿‡ OpenAI å…¼å®¹æ ¼å¼çš„ä»£ç†ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ ‡å‡†çš„ OpenAI SDK è®¿é—®è¿™äº› Claude æ¨¡å‹ã€‚

---

## âœ… æ”¯æŒçš„æ¨¡å‹ï¼ˆå·²éªŒè¯å¯ç”¨ï¼‰

### ğŸ¤– Claude æ¨¡å‹

| æ¨¡å‹ ID | ç‰ˆæœ¬ | ä¸Šä¸‹æ–‡ | çŠ¶æ€ | è¯´æ˜ |
|---------|------|--------|------|------|
| **`claude-sonnet-4-5-20250929`** â­ | Claude Sonnet 4.5 | 200K | âœ… å·²éªŒè¯ | **å¼ºçƒˆæ¨è** - æœ€æ–°æœ€å¼º |
| **`claude-sonnet-4-20250514`** | Claude Sonnet 4 | 200K | âœ… å·²éªŒè¯ | ç¨³å®šå¯é  |
| **`claude-3-7-sonnet-20250219`** | Claude 3.7 Sonnet | 200K | âœ… å·²éªŒè¯ | æ€§èƒ½ä¼˜ç§€ |

> ğŸ“ **æµ‹è¯•æ—¥æœŸ**: 2025-10-08  
> ğŸ” **æµ‹è¯•æ–¹æ³•**: çœŸå® API è°ƒç”¨  
> âœ… **å¯ç”¨æ¨¡å‹**: 3 ä¸ª

---

## ğŸ¯ æ¨¡å‹é€‰æ‹©å»ºè®®

### ğŸ† æ¨èä½¿ç”¨ï¼šClaude Sonnet 4.5

```python
model = "claude-sonnet-4-5-20250929"  # å¼ºçƒˆæ¨è
```

**é€‚ç”¨åœºæ™¯**:
- âœ… æ—¥å¸¸å¯¹è¯
- âœ… ä»£ç ç”Ÿæˆä¸åˆ†æ
- âœ… æ–‡æ¡£å¤„ç†
- âœ… é•¿æ–‡æœ¬åˆ†æ
- âœ… å¤æ‚æ¨ç†ä»»åŠ¡

**ä¼˜åŠ¿**:
- ğŸš€ æœ€æ–°ç‰ˆæœ¬ï¼Œæ€§èƒ½æœ€å¼º
- ğŸ“Š 200K tokens ä¸Šä¸‹æ–‡
- ğŸ’¡ å…¨èƒ½å‹ï¼Œé€‚åˆ 90% çš„åœºæ™¯

---

## ğŸ“– ä½¿ç”¨ç¤ºä¾‹

### Python (OpenAI SDK)

```python
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_PROXY_API_KEY",
    base_url="http://localhost:8003/v1"
)

# ä½¿ç”¨ Claude Sonnet 4.5 (æ¨è)
response = client.chat.completions.create(
    model="claude-sonnet-4-5-20250929",
    messages=[
        {"role": "user", "content": "Hello! ç”¨ä¸­æ–‡ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}
    ],
    max_tokens=1024
)

print(response.choices[0].message.content)
```

### æµå¼å“åº”

```python
# æµå¼è¾“å‡º - å®æ—¶æ˜¾ç¤ºç”Ÿæˆè¿‡ç¨‹
stream = client.chat.completions.create(
    model="claude-sonnet-4-5-20250929",
    messages=[{"role": "user", "content": "å†™ä¸€é¦–å…³äºç¼–ç¨‹çš„è¯—"}],
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
```

### cURL

```bash
# éæµå¼è¯·æ±‚
curl -X POST http://localhost:8003/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_PROXY_API_KEY" \
  -d '{
    "model": "claude-sonnet-4-5-20250929",
    "messages": [{"role": "user", "content": "Hello!"}],
    "max_tokens": 1024,
    "stream": false
  }'

# æµå¼è¯·æ±‚
curl -N -X POST http://localhost:8003/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_PROXY_API_KEY" \
  -d '{
    "model": "claude-sonnet-4-5-20250929",
    "messages": [{"role": "user", "content": "è®²ä¸ªç¬‘è¯"}],
    "stream": true
  }'
```

### Node.js

```javascript
import OpenAI from 'openai';

const client = new OpenAI({
  apiKey: process.env.PROXY_API_KEY,
  baseURL: 'http://localhost:8003/v1'
});

// éæµå¼
const response = await client.chat.completions.create({
  model: 'claude-sonnet-4-5-20250929',
  messages: [{ role: 'user', content: 'Hello!' }]
});

console.log(response.choices[0].message.content);

// æµå¼
const stream = await client.chat.completions.create({
  model: 'claude-sonnet-4-5-20250929',
  messages: [{ role: 'user', content: 'Hello!' }],
  stream: true
});

for await (const chunk of stream) {
  if (chunk.choices[0]?.delta?.content) {
    process.stdout.write(chunk.choices[0].delta.content);
  }
}
```

---

## ğŸ”„ å¿«é€Ÿåˆ‡æ¢æ¨¡å‹

æ‰€æœ‰æ¨¡å‹ä½¿ç”¨ç›¸åŒçš„ API æ ¼å¼ï¼Œåªéœ€æ›´æ”¹ `model` å‚æ•°ï¼š

```python
# æµ‹è¯•ä¸åŒæ¨¡å‹
models_to_try = [
    "claude-sonnet-4-5-20250929",   # æ¨è â­
    "claude-sonnet-4-20250514",     # Claude 4
    "claude-3-7-sonnet-20250219"    # Claude 3.7
]

for model in models_to_try:
    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": "ä½ å¥½"}],
        max_tokens=200
    )
    print(f"\næ¨¡å‹: {model}")
    print(response.choices[0].message.content)
```

---

## âš™ï¸ è¯·æ±‚å‚æ•°

æ‰€æœ‰æ¨¡å‹æ”¯æŒä»¥ä¸‹æ ‡å‡†å‚æ•°ï¼š

```python
response = client.chat.completions.create(
    model="claude-sonnet-4-5-20250929",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
    ],
    max_tokens=4096,       # æœ€å¤§è¾“å‡ºé•¿åº¦
    temperature=0.7,       # éšæœºæ€§ (0-2)
    top_p=1.0,            # æ ¸é‡‡æ ·
    stream=False,         # æ˜¯å¦æµå¼è¾“å‡º
    stop=None             # åœæ­¢è¯
)
```

### æ¨èçš„ max_tokens è®¾ç½®

```python
# ç®€çŸ­å¯¹è¯
max_tokens = 1024      
# ~1K tokens

# æ ‡å‡†å“åº” (æ¨è)
max_tokens = 4096      # ~4K tokens

# é•¿æ–‡æœ¬ç”Ÿæˆ
max_tokens = 8192      # ~8K tokens
```

---

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **æ¨¡å‹å¯ç”¨æ€§**: ç›®å‰ä»…æ”¯æŒ 3 ä¸ª Claude æ¨¡å‹ï¼ˆç»çœŸå®æµ‹è¯•éªŒè¯ï¼‰
2. **API å…¼å®¹æ€§**: å®Œå…¨å…¼å®¹ OpenAI SDK å’Œ API æ ¼å¼
3. **ä¸Šä¸‹æ–‡é•¿åº¦**: æ‰€æœ‰æ¨¡å‹æ”¯æŒ 200K tokens ä¸Šä¸‹æ–‡
4. **æµå¼æ”¯æŒ**: æ‰€æœ‰æ¨¡å‹éƒ½æ”¯æŒæµå¼ï¼ˆ`stream: true`ï¼‰å’Œéæµå¼å“åº”
5. **æˆæœ¬ä¼˜åŒ–**: ä½¿ç”¨åˆé€‚çš„ `max_tokens` å‚æ•°æ§åˆ¶æˆæœ¬

---

## â“ å¸¸è§é—®é¢˜

### Q: ä¸ºä»€ä¹ˆåªæ”¯æŒè¿™ 3 ä¸ªæ¨¡å‹ï¼Ÿ

A: ç»è¿‡ 2025-10-08 çš„çœŸå® API æµ‹è¯•ï¼ŒFactory AI åç«¯ä»…è¿™ 3 ä¸ª Claude æ¨¡å‹è¿”å›æ­£å¸¸å“åº”ã€‚å…¶ä»–æ¨¡å‹ï¼ˆåŒ…æ‹¬ GPTã€Geminiã€Grok ç­‰ï¼‰å‡è¿”å›é”™è¯¯æˆ–è¶…æ—¶ã€‚

### Q: æ¨èä½¿ç”¨å“ªä¸ªæ¨¡å‹ï¼Ÿ

A: **å¼ºçƒˆæ¨è** `claude-sonnet-4-5-20250929`ï¼Œå®ƒæ˜¯æœ€æ–°ç‰ˆæœ¬ï¼Œæ€§èƒ½æœ€å¼ºï¼Œé€‚åˆå‡ ä¹æ‰€æœ‰åœºæ™¯ã€‚

### Q: æ”¯æŒæµå¼å“åº”å—ï¼Ÿ

A: æ˜¯çš„ï¼æ‰€æœ‰ 3 ä¸ªæ¨¡å‹éƒ½æ”¯æŒæµå¼å“åº”ã€‚åªéœ€è®¾ç½® `stream: true` å‚æ•°ã€‚è¯¦è§ [æµå¼åŠŸèƒ½æ–‡æ¡£](STREAMING.md)ã€‚

### Q: å¦‚ä½•å¤„ç†é•¿æ–‡æœ¬ï¼Ÿ

A: æ‰€æœ‰æ¨¡å‹éƒ½æ”¯æŒ 200K tokens ä¸Šä¸‹æ–‡ï¼Œè¶³ä»¥å¤„ç†å¤§å¤šæ•°é•¿æ–‡æœ¬åœºæ™¯ã€‚

### Q: å…¶ä»–æ¨¡å‹ä»€ä¹ˆæ—¶å€™æ”¯æŒï¼Ÿ

A: è¿™å–å†³äº Factory AI å®˜æ–¹ã€‚å»ºè®®å…³æ³¨ Factory AI çš„æ›´æ–°å…¬å‘Šï¼Œæˆ–æŸ¥çœ‹æˆ‘ä»¬çš„ [SUPPORTED_MODELS.md](SUPPORTED_MODELS.md) æ–‡æ¡£äº†è§£æœ€æ–°æµ‹è¯•ç»“æœã€‚

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [æ”¯æŒçš„æ¨¡å‹è¯¦ç»†æµ‹è¯•æŠ¥å‘Š](SUPPORTED_MODELS.md) - å®Œæ•´çš„æµ‹è¯•ç»“æœå’Œåˆ†æ
- [å¿«é€Ÿå¼€å§‹](QUICK_START.md) - 5åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹
- [æµå¼åŠŸèƒ½](STREAMING.md) - æµå¼å“åº”ä½¿ç”¨æŒ‡å—
- [API Key ä»£ç†](API-KEY-PROXY.md) - API Key ç®¡ç†è¯´æ˜
- [OpenAI å…¼å®¹æ¨¡å¼](README-OpenAI.md) - OpenAI SDK ä½¿ç”¨æŒ‡å—

---

## ğŸ“ˆ æµ‹è¯•è®°å½•

**æµ‹è¯•æ—¥æœŸ**: 2025-10-08  
**æµ‹è¯•æ–¹æ³•**: çœŸå® API è°ƒç”¨  
**æ€»æµ‹è¯•æ•°**: 27 ä¸ªæ¨¡å‹  

### âœ… å¯ç”¨æ¨¡å‹ï¼ˆ3ä¸ªï¼‰

| æ¨¡å‹ ID | æµ‹è¯•çŠ¶æ€ | å“åº” | å¤‡æ³¨ |
|---------|---------|------|------|
| `claude-sonnet-4-5-20250929` | âœ… é€šè¿‡ | æ­£å¸¸ | â­ æ¨è |
| `claude-sonnet-4-20250514` | âœ… é€šè¿‡ | æ­£å¸¸ | ç¨³å®š |
| `claude-3-7-sonnet-20250219` | âœ… é€šè¿‡ | æ­£å¸¸ | å¯é  |

### âŒ ä¸å¯ç”¨æ¨¡å‹ï¼ˆ24ä¸ªï¼‰

ä»¥ä¸‹æ¨¡å‹ç»æµ‹è¯•å‡ä¸å¯ç”¨ï¼š

**Claude å…¶ä»–ç‰ˆæœ¬ï¼ˆ5ä¸ªï¼‰**:
- `claude-3-5-sonnet-20241022`, `claude-3-5-sonnet-20250219`
- `claude-sonnet-4-1-20250514`
- `claude-3-5-haiku-20241022`, `claude-3-haiku-20240307`
- åŸå› : HTTP 400 - Unsupported OpenAI model ID

**OpenAI/GPT ç³»åˆ—ï¼ˆ10ä¸ªï¼‰**:
- `gpt-5-*`, `o1-*`, `o3-*`, `o4-*`, `gpt-4o-*`
- åŸå› : è¶…æ—¶ï¼ˆ30ç§’æ— å“åº”ï¼‰- Responses API ç«¯ç‚¹é—®é¢˜

**Gemini ç³»åˆ—ï¼ˆ4ä¸ªï¼‰**:
- `gemini-2.5-*`, `gemini-2.0-*`, `gemini-exp-*`
- åŸå› : HTTP 405 - Method not allowed

**Grok ç³»åˆ—ï¼ˆ3ä¸ªï¼‰**:
- `grok-4`, `grok-beta`, `grok-vision-beta`
- åŸå› : HTTP 405/400

**å…¶ä»–ï¼ˆ2ä¸ªï¼‰**:
- `glm-4.6`, ç­‰
- åŸå› : HTTP 400

è¯¦ç»†æµ‹è¯•æŠ¥å‘Šè¯·æŸ¥çœ‹: [SUPPORTED_MODELS.md](SUPPORTED_MODELS.md)

---

**æœ€åæ›´æ–°**: 2025-10-08  
**æ”¯æŒçš„æ¨¡å‹æ•°**: 3 ä¸ªï¼ˆClaude ç³»åˆ—ï¼‰  
**æµ‹è¯•éªŒè¯**: âœ… å®Œæˆ